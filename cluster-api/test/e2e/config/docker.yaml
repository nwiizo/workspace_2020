---
# CI E2E test test configuration scenario using locally build images and manifests for:
# - cluster-api
# - bootstrap kubeadm
# - control-plane kubeadm
# - docker

# For creating local dev images run make docker-build-e2e from the main CAPI repository

images:
# Use local dev images built source tree;
- name: gcr.io/k8s-staging-cluster-api/cluster-api-controller-amd64:dev
  loadBehavior: mustLoad
- name: gcr.io/k8s-staging-cluster-api/kubeadm-bootstrap-controller-amd64:dev
  loadBehavior: mustLoad
- name: gcr.io/k8s-staging-cluster-api/kubeadm-control-plane-controller-amd64:dev
  loadBehavior: mustLoad
- name: gcr.io/k8s-staging-cluster-api/capd-manager-amd64:dev
  loadBehavior: mustLoad
- name: quay.io/jetstack/cert-manager-cainjector:v0.16.1
  loadBehavior: tryLoad
- name: quay.io/jetstack/cert-manager-webhook:v0.16.1
  loadBehavior: tryLoad
- name: quay.io/jetstack/cert-manager-controller:v0.16.1
  loadBehavior: tryLoad

providers:

- name: cluster-api
  type: CoreProvider
  versions:
  - name: v0.3.0
  # Use manifest from source files
    value: ../../../config
    replacements:
    - old: --metrics-bind-addr=127.0.0.1:8080
      new: --metrics-bind-addr=:8080

- name: kubeadm
  type: BootstrapProvider
  versions:
  - name: v0.3.0
  # Use manifest from source files
    value: ../../../bootstrap/kubeadm/config
    replacements:
    - old: --metrics-bind-addr=127.0.0.1:8080
      new: --metrics-bind-addr=:8080

- name: kubeadm
  type: ControlPlaneProvider
  versions:
  - name: v0.3.0
  # Use manifest from source files
    value: ../../../controlplane/kubeadm/config
    replacements:
    - old: --metrics-bind-addr=127.0.0.1:8080
      new: --metrics-bind-addr=:8080

- name: docker
  type: InfrastructureProvider
  versions:
  - name: v0.3.0
  # Use manifest from source files
    value: ../../../test/infrastructure/docker/config
    replacements:
    - old: --metrics-bind-addr=127.0.0.1:8080
      new: --metrics-bind-addr=:8080
  files:
  # Add cluster templates
  - sourcePath: "../data/infrastructure-docker/v1alpha4/cluster-template.yaml"
  - sourcePath: "../data/infrastructure-docker/v1alpha4/cluster-template-mhc.yaml"
  - sourcePath: "../data/infrastructure-docker/v1alpha4/cluster-template-kcp-adoption.yaml"
  - sourcePath: "../data/infrastructure-docker/v1alpha4/cluster-template-machine-pool.yaml"
  - sourcePath: "../data/infrastructure-docker/v1alpha4/cluster-template-node-drain.yaml"

variables:
  KUBERNETES_VERSION: "v1.19.1"
  ETCD_VERSION_UPGRADE_TO: "3.4.9-0"
  COREDNS_VERSION_UPGRADE_TO: "1.7.0"
  KUBERNETES_VERSION_UPGRADE_TO: "v1.19.1"
  KUBERNETES_VERSION_UPGRADE_FROM: "v1.18.2"
  DOCKER_SERVICE_DOMAIN: "cluster.local"
  DOCKER_SERVICE_CIDRS: "10.128.0.0/12"
  # IMPORTANT! This values should match the one used by the CNI provider
  DOCKER_POD_CIDRS: "192.168.0.0/16"
  CNI: "./data/cni/kindnet/kindnet.yaml"
  EXP_CLUSTER_RESOURCE_SET: "true"
  EXP_MACHINE_POOL: "true"
  KUBETEST_CONFIGURATION: "./data/kubetest/conformance.yaml"
  NODE_DRAIN_TIMEOUT: "60s"

intervals:
  default/wait-controllers: ["3m", "10s"]
  default/wait-cluster: ["5m", "10s"]
  default/wait-control-plane: ["10m", "10s"]
  default/wait-worker-nodes: ["5m", "10s"]
  default/wait-machine-pool-nodes: ["5m", "10s"]
  default/wait-delete-cluster: ["3m", "10s"]
  default/wait-machine-upgrade: ["20m", "10s"]
  default/wait-machine-pool-upgrade: ["5m", "10s"]
  default/wait-machine-remediation: ["5m", "10s"]
  node-drain/wait-deployment-available: ["3m", "10s"]
  node-drain/wait-control-plane: ["15m", "10s"]
